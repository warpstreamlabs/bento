input:
  generate:
    mapping: |
        root = "{\"name\":\"Alice\",\"age\":50}"
    interval: 100ms
    count: 12
    batch_size: 3

pipeline:
  processors:

    - mapping: |
        let tables = ["test_1", "test_2", "test_3"]
        meta destination_table = $tables.index(random_int(seed:timestamp_unix_nano()) % $tables.length())

    - log:
        message: ${! metadata("destination_table") }

output:
  gcp_bigquery_batch:
    dataset: "test"
    table: ${! metadata("destination_table") }
