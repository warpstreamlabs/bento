---
title: genkit_ollama
slug: genkit_ollama
type: processor
status: beta
categories: ["AI","Genkit"]
---

<!--
     THIS FILE IS AUTOGENERATED!

     To make changes please edit the corresponding source file under internal/impl/<provider>.
-->

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

:::caution BETA
This component is mostly stable but breaking changes could still be made outside of major version releases if a fundamental problem with the component is found.
:::
Generates content using Ollama models.

```yml
# Config fields, showing default values
label: ""
genkit_ollama:
  address: http://localhost:11434
  type: generate
  model: "" # No default (required)
  config:
    max_output_tokens: 0 # No default (optional)
    stop_sequences: [] # No default (optional)
    temperature: 0 # No default (optional)
    top_k: 0 # No default (optional)
    top_p: 0 # No default (optional)
  prompt: "" # No default (required)
  tools: [] # No default (optional)
  output:
    schema: null # No default (optional)
    format: text
    instructions: "" # No default (optional)
```

Generates text content using Ollama models through the Genkit framework. For more information about Genkit, see https://genkit.dev and https://github.com/firebase/genkit.

## Examples

<Tabs defaultValue="Chat Completion with Ollama" values={[
{ label: 'Chat Completion with Ollama', value: 'Chat Completion with Ollama', },
]}>

<TabItem value="Chat Completion with Ollama">


Generate text using Ollama models in chat mode:

```yaml
pipeline:
  processors:
    - genkit_ollama:
        address: "http://localhost:11434"
        model: "llama3.2"
        type: "chat"
        config:
          temperature: 0.7
          max_output_tokens: 256
        prompt: |
          {{role "system"}}
          You are a helpful assistant.
          {{role "user"}}
          ${! content() }
```


</TabItem>
</Tabs>

## Fields

### `address`

Server address of Ollama instance.


Type: `string`  
Default: `"http://localhost:11434"`  

### `type`

The type of task the model should perform.


Type: `string`  
Default: `"generate"`  
Options: `chat`, `generate`.

### `model`

Model identifier.


Type: `string`  

### `config`

Model configuration matching common Genkit parameters.


Type: `object`  

### `config.max_output_tokens`

Maximum tokens the model can output.


Type: `int`  

### `config.stop_sequences`

List of stop sequences.


Type: `array`  

### `config.temperature`

Controls randomness (0.0 to 1.0).


Type: `float`  

### `config.top_k`

Top-K sampling parameter.


Type: `int`  

### `config.top_p`

Top-P sampling parameter.


Type: `float`  

### `prompt`

Prompt template. use bento bloblang interpolation for injecting in custom data.
This field supports [interpolation functions](/docs/configuration/interpolation#bloblang-queries).


Type: `string`  

### `tools`

A map of processors that the model can utilise as tools.


Type: `array`  

### `tools[].processor`

Sorry! This field is missing documentation.


Type: `processor`  

### `tools[].name`

Sorry! This field is missing documentation.


Type: `string`  

### `tools[].description`

Sorry! This field is missing documentation.


Type: `string`  

### `output`

Determines the schema/format of the output.


Type: `object`  

### `output.schema`

Output schema in Picoschema format.


Type: `unknown`  

### `output.format`

The format of the response.


Type: `string`  
Default: `"text"`  
Options: `json`, `jsonl`, `text`, `array`, `enum`.

### `output.instructions`

Instructions for the model output.
This field supports [interpolation functions](/docs/configuration/interpolation#bloblang-queries).


Type: `string`  


