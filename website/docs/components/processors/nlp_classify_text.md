---
title: nlp_classify_text
slug: nlp_classify_text
type: processor
status: beta
categories: ["Machine Learning","NLP"]
---

<!--
     THIS FILE IS AUTOGENERATED!

     To make changes please edit the corresponding source file under internal/impl/<provider>.
-->

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

:::caution BETA
This component is mostly stable but breaking changes could still be made outside of major version releases if a fundamental problem with the component is found.
:::
Performs text classification using a Hugging Face ðŸ¤— NLP pipeline with an ONNX Runtime model.

Introduced in version v1.11.0.


<Tabs defaultValue="common" values={[
  { label: 'Common', value: 'common', },
  { label: 'Advanced', value: 'advanced', },
]}>

<TabItem value="common">

```yml
# Common config fields, showing default values
label: ""
nlp_classify_text:
  name: "" # No default (optional)
  path: /path/to/models/my_model.onnx # No default (required)
  aggregation_function: SOFTMAX
  multi_label: false
```

</TabItem>
<TabItem value="advanced">

```yml
# All config fields, showing default values
label: ""
nlp_classify_text:
  name: "" # No default (optional)
  path: /path/to/models/my_model.onnx # No default (required)
  enable_download: false
  download_options:
    repository: KnightsAnalytics/distilbert-NER # No default (required)
    onnx_filepath: model.onnx
  aggregation_function: SOFTMAX
  multi_label: false
```

</TabItem>
</Tabs>

### Text Classification
Text Classification is the task of assigning a label or class to a given text. Some use cases are sentiment analysis, natural language inference, and assessing grammatical correctness.
This processor runs text-classification inference against batches of text data, returning labelled classification corresponding to each input.
This component uses [Hugot](https://github.com/knights-analytics/hugot), a library that provides an interface for running [Open Neural Network Exchange (ONNX) models](https://onnx.ai/onnx/intro/) and transformer pipelines, with a focus on NLP tasks.

Currently, [Bento only implements](https://github.com/knights-analytics/hugot/tree/main?tab=readme-ov-file#implemented-pipelines):
	
- [featureExtraction](https://huggingface.co/docs/transformers/en/main_classes/pipelines#transformers.FeatureExtractionPipeline)
- [textClassification](https://huggingface.co/docs/transformers/en/main_classes/pipelines#transformers.TextClassificationPipeline)
- [tokenClassification](https://huggingface.co/docs/transformers/en/main_classes/pipelines#transformers.TokenClassificationPipeline)
- [zeroShotClassification](https://huggingface.co/docs/transformers/en/main_classes/pipelines#transformers.ZeroShotClassificationPipeline)

### What is a pipeline?
From [HuggingFace docs](https://huggingface.co/docs/transformers/en/main_classes/pipelines):
> A pipeline in ðŸ¤— Transformers is an abstraction referring to a series of steps that are executed in a specific order to preprocess and transform data and return a prediction from a model. Some example stages found in a pipeline might be data preprocessing, feature extraction, and normalization.

:::warning
While, only models in [ONNX](https://onnx.ai/) format are supported, exporting existing formats to ONNX is both possible and straightforward in most standard ML libraries. For more on this, check out the [ONNX conversion docs](https://onnx.ai/onnx/intro/converters.html). 
Otherwise, check out using [HuggingFace Optimum](https://huggingface.co/docs/optimum/en/exporters/onnx/usage_guides/export_a_model) for easy model conversion.
:::


## Examples

<Tabs defaultValue="Emotion Scoring (Local Model)" values={[
{ label: 'Emotion Scoring (Local Model)', value: 'Emotion Scoring (Local Model)', },
{ label: 'Sentiment Analysis (Downloaded Model)', value: 'Sentiment Analysis (Downloaded Model)', },
]}>

<TabItem value="Emotion Scoring (Local Model)">

Here, we load the [Cohee/distilbert-base-uncased-go-emotions-onnx](https://huggingface.co/Cohee/distilbert-base-uncased-go-emotions-onnx) model from the local directory at `models/coheedistilbert_base_uncased_go_emotions_onnx`.The processor returns a single-label output with the highest emotion score for the text. 

```yaml
pipeline:
  processors:
    - nlp_classify_text:
        name: classify-incoming-data
        path: "models/coheedistilbert_base_uncased_go_emotions_onnx"

# In: "I'm super excited for my Bento box!"
# Out: [{"Label":"excitement","Score":0.34134513}]
```

</TabItem>
<TabItem value="Sentiment Analysis (Downloaded Model)">

Here, we retrieve the [KnightsAnalytics/distilbert-base-uncased-finetuned-sst-2-english](https://huggingface.co/KnightsAnalytics/distilbert-base-uncased-finetuned-sst-2-english) model from HuggingFace and store it in a `./models` directory.The processor returns a multi-label output indicating showing a `POSITIVE` and `NEGATIVE` score some input text-data.

```yaml
pipeline:
  processors:
    - nlp_classify_text:
        name: classify-multi-label
        path: "./models"
        multi_label: true
        enable_download: true
        download_options:
          repository: "KnightsAnalytics/distilbert-base-uncased-finetuned-sst-2-english"


# In: "This meal tastes like old boots."
# Out: [{"Label":"NEGATIVE","Score":0.9977291},{"Label":"POSITIVE","Score":0.0022708932}]
```

</TabItem>
</Tabs>

## Fields

### `name`

Name of the hugot pipeline. Defaults to a random UUID if not set.


Type: `string`  

### `path`

Path to the ONNX model file, or directory containing the model. When downloading (`enable_download: true`), this becomes the destination and must be a directory.


Type: `string`  

```yml
# Examples

path: /path/to/models/my_model.onnx

path: /path/to/models/
```

### `enable_download`

When enabled, attempts to download an ONNX Runtime compatible model from HuggingFace specified in `repository`.


Type: `bool`  
Default: `false`  

### `download_options`

Options used to download a model directly from HuggingFace. Before the model is downloaded, validation occurs to ensure the remote repository contains both an`.onnx` and `tokenizers.json` file.


Type: `object`  

### `download_options.repository`

The name of the huggingface model repository.


Type: `string`  

```yml
# Examples

repository: KnightsAnalytics/distilbert-NER

repository: KnightsAnalytics/distilbert-base-uncased-finetuned-sst-2-english

repository: sentence-transformers/all-MiniLM-L6-v2
```

### `download_options.onnx_filepath`

Filepath of the ONNX model within the repository. Only needed when multiple `.onnx` files exist.


Type: `string`  
Default: `"model.onnx"`  

```yml
# Examples

onnx_filepath: onnx/model.onnx

onnx_filepath: onnx/model_quantized.onnx

onnx_filepath: onnx/model_fp16.onnx
```

### `aggregation_function`

The aggregation function to use for the text classification pipeline.


Type: `string`  
Default: `"SOFTMAX"`  
Options: `SOFTMAX`, `SIGMOID`.

### `multi_label`

Whether a text classification pipeline should return multiple labels. If false, only the label-pair with the highest score is returned.


Type: `bool`  
Default: `false`  


