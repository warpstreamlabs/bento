---
title: broker
slug: broker
type: output
status: stable
categories: ["Utility"]
---

<!--
     THIS FILE IS AUTOGENERATED!

     To make changes please edit the corresponding source file under internal/impl/<provider>.
-->

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

Allows you to route messages to multiple child outputs using a range of brokering [patterns](#patterns).


<Tabs defaultValue="common" values={[
  { label: 'Common', value: 'common', },
  { label: 'Advanced', value: 'advanced', },
]}>

<TabItem value="common">

```yml
# Common config fields, showing default values
output:
  label: ""
  broker:
    pattern: fan_out
    outputs: [] # No default (required)
    batching:
      count: 0
      byte_size: 0
      period: ""
      jitter: 0
      check: ""
```

</TabItem>
<TabItem value="advanced">

```yml
# All config fields, showing default values
output:
  label: ""
  broker:
    copies: 1
    pattern: fan_out
    outputs: [] # No default (required)
    batching:
      count: 0
      byte_size: 0
      period: ""
      jitter: 0
      check: ""
      processors: [] # No default (optional)
```

</TabItem>
</Tabs>

Outputs can be defined inline with their full configuration or referenced by resource name. Both methods can be mixed:

```yaml
output:
  broker:
    pattern: fan_out
    outputs:
      # Inline output configurations
      - kafka:
          addresses: [ "localhost:9092" ]
          topic: topic_a
      - kafka:
          addresses: [ "localhost:9092" ]
          topic: topic_b
      # Or use resource references
      - resource: my_http_output
```

[Processors](/docs/components/processors/about) can be listed to apply across individual outputs or all outputs:

```yaml
output:
  broker:
    pattern: fan_out
    outputs:
      - resource: foo
      - resource: bar
        # Processors only applied to messages sent to bar.
        processors:
          - resource: bar_processor

  # Processors applied to messages sent to all brokered outputs.
  processors:
    - resource: general_processor
```

## Examples

<Tabs defaultValue="Send to Multiple Destinations" values={[
{ label: 'Send to Multiple Destinations', value: 'Send to Multiple Destinations', },
{ label: 'Load Balance Across Endpoints', value: 'Load Balance Across Endpoints', },
]}>

<TabItem value="Send to Multiple Destinations">

Send the same data to multiple outputs simultaneously.

```yaml
output:
  broker:
    pattern: fan_out
    outputs:
      - gcp_bigquery:
          project: my-project
          dataset: raw_data
          table: events
      - gcp_bigquery:
          project: my-project
          dataset: analytics
          table: events_aggregated
      - file:
          path: /backup/events.jsonl
          codec: lines
```

</TabItem>
<TabItem value="Load Balance Across Endpoints">

Distribute messages across multiple targets.

```yaml
output:
  broker:
    pattern: round_robin
    outputs:
      - http_client:
          url: http://api1.example.com/data
      - http_client:
          url: http://api2.example.com/data
      - http_client:
          url: http://api3.example.com/data
```

</TabItem>
</Tabs>

## Fields

### `copies`

The number of copies of each configured output to spawn.


Type: `int`  
Default: `1`  

### `pattern`

The brokering pattern to use.


Type: `string`  
Default: `"fan_out"`  
Options: `fan_out`, `fan_out_fail_fast`, `fan_out_sequential`, `fan_out_sequential_fail_fast`, `round_robin`, `greedy`.

### `outputs`

A list of child outputs to broker. Each item can be either a complete inline output configuration or a reference to an output resource.


Type: `array`  

### `batching`

Allows you to configure a [batching policy](/docs/configuration/batching).


Type: `object`  

```yml
# Examples

batching:
  byte_size: 5000
  count: 0
  period: 1s

batching:
  count: 10
  period: 1s

batching:
  check: this.contains("END BATCH")
  count: 0
  period: 1m

batching:
  count: 10
  jitter: 0.1
  period: 10s
```

### `batching.count`

A number of messages at which the batch should be flushed. If `0` disables count based batching.


Type: `int`  
Default: `0`  

### `batching.byte_size`

An amount of bytes at which the batch should be flushed. If `0` disables size based batching.


Type: `int`  
Default: `0`  

### `batching.period`

A period in which an incomplete batch should be flushed regardless of its size.


Type: `string`  
Default: `""`  

```yml
# Examples

period: 1s

period: 1m

period: 500ms
```

### `batching.jitter`

A non-negative factor that adds random delay to batch flush intervals, where delay is determined uniformly at random between `0` and `jitter * period`. For example, with `period: 100ms` and `jitter: 0.1`, each flush will be delayed by a random duration between `0-10ms`.


Type: `float`  
Default: `0`  

```yml
# Examples

jitter: 0.01

jitter: 0.1

jitter: 1
```

### `batching.check`

A [Bloblang query](/docs/guides/bloblang/about/) that should return a boolean value indicating whether a message should end a batch.


Type: `string`  
Default: `""`  

```yml
# Examples

check: this.type == "end_of_transaction"
```

### `batching.processors`

A list of [processors](/docs/components/processors/about) to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.


Type: `array`  

```yml
# Examples

processors:
  - archive:
      format: concatenate

processors:
  - archive:
      format: lines

processors:
  - archive:
      format: json_array
```

## Patterns

The broker pattern determines the way in which messages are allocated and can be chosen from the following:

### `fan_out`

With the fan out pattern all outputs will be sent every message that passes through Bento in parallel.

If an output applies back pressure it will block all subsequent messages, and if an output fails to send a message it will be retried continuously until completion or service shut down. This mechanism is in place in order to prevent one bad output from causing a larger retry loop that results in a good output from receiving unbounded message duplicates.

Sometimes it is useful to disable the back pressure or retries of certain fan out outputs and instead drop messages that have failed or were blocked. In this case you can wrap outputs with a [`drop_on` output](/docs/components/outputs/drop_on).

### `fan_out_fail_fast`

The same as the `fan_out` pattern, except that output failures will not be automatically retried. This pattern should be used with caution as busy retry loops could result in unlimited duplicates being introduced into the non-failure outputs.

### `fan_out_sequential`

Similar to the fan out pattern except outputs are written to sequentially, meaning an output is only written to once the preceding output has confirmed receipt of the same message.

If an output applies back pressure it will block all subsequent messages, and if an output fails to send a message it will be retried continuously until completion or service shut down. This mechanism is in place in order to prevent one bad output from causing a larger retry loop that results in a good output from receiving unbounded message duplicates.

### `fan_out_sequential_fail_fast`

The same as the `fan_out_sequential` pattern, except that output failures will not be automatically retried. This pattern should be used with caution as busy retry loops could result in unlimited duplicates being introduced into the non-failure outputs.

### `round_robin`

With the round robin pattern each message will be assigned a single output following their order. If an output applies back pressure it will block all subsequent messages. If an output fails to send a message then the message will be re-attempted with the next input, and so on.

### `greedy`

The greedy pattern results in higher output throughput at the cost of potentially disproportionate message allocations to those outputs. Each message is sent to a single output, which is determined by allowing outputs to claim messages as soon as they are able to process them. This results in certain faster outputs potentially processing more messages at the cost of slower outputs.

